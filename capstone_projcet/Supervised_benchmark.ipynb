{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/nyaribomaseru/Documents/AWS_Sagemaker_Deployment/Bertelsmann_Arvato_Project/data/'\n",
    "mailout_train_df =  pd.read_csv( file_path + '../data/reduced_mailout_train.csv',index_col='LNR')\n",
    "mailout_test_df =  pd.read_csv( file_path + '../data/reduced_mailout_test.csv',index_col='LNR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_0</th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>c_6</th>\n",
       "      <th>c_7</th>\n",
       "      <th>c_8</th>\n",
       "      <th>c_9</th>\n",
       "      <th>...</th>\n",
       "      <th>c_161</th>\n",
       "      <th>c_162</th>\n",
       "      <th>c_163</th>\n",
       "      <th>c_164</th>\n",
       "      <th>c_165</th>\n",
       "      <th>c_166</th>\n",
       "      <th>c_167</th>\n",
       "      <th>c_168</th>\n",
       "      <th>c_169</th>\n",
       "      <th>c_170</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LNR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.002040</td>\n",
       "      <td>0.695311</td>\n",
       "      <td>0.141709</td>\n",
       "      <td>-0.248340</td>\n",
       "      <td>-0.078177</td>\n",
       "      <td>-0.186636</td>\n",
       "      <td>-0.228007</td>\n",
       "      <td>-0.041814</td>\n",
       "      <td>0.040093</td>\n",
       "      <td>-0.150729</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000169</td>\n",
       "      <td>0.002116</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.005166</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>-0.002449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.007755</td>\n",
       "      <td>0.700742</td>\n",
       "      <td>0.142745</td>\n",
       "      <td>-0.246705</td>\n",
       "      <td>-0.077638</td>\n",
       "      <td>-0.182470</td>\n",
       "      <td>-0.227757</td>\n",
       "      <td>-0.039235</td>\n",
       "      <td>0.042738</td>\n",
       "      <td>-0.147917</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002663</td>\n",
       "      <td>0.005137</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.004773</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>0.002956</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.996326</td>\n",
       "      <td>0.689880</td>\n",
       "      <td>0.140674</td>\n",
       "      <td>-0.249976</td>\n",
       "      <td>-0.078717</td>\n",
       "      <td>-0.190801</td>\n",
       "      <td>-0.228257</td>\n",
       "      <td>-0.044394</td>\n",
       "      <td>0.037447</td>\n",
       "      <td>-0.153542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>-0.000905</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.007515</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.002879</td>\n",
       "      <td>-0.001272</td>\n",
       "      <td>-0.000802</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>-0.005690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.970465</td>\n",
       "      <td>0.785248</td>\n",
       "      <td>-0.197447</td>\n",
       "      <td>0.129687</td>\n",
       "      <td>-0.091095</td>\n",
       "      <td>-0.286309</td>\n",
       "      <td>-0.271982</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>0.030960</td>\n",
       "      <td>-0.250130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>-0.008212</td>\n",
       "      <td>-0.002803</td>\n",
       "      <td>-0.007783</td>\n",
       "      <td>-0.004655</td>\n",
       "      <td>-0.003404</td>\n",
       "      <td>-0.002669</td>\n",
       "      <td>-0.002122</td>\n",
       "      <td>-0.001001</td>\n",
       "      <td>0.002806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.996326</td>\n",
       "      <td>0.689880</td>\n",
       "      <td>0.140674</td>\n",
       "      <td>-0.249976</td>\n",
       "      <td>-0.078717</td>\n",
       "      <td>-0.190801</td>\n",
       "      <td>-0.228257</td>\n",
       "      <td>-0.044394</td>\n",
       "      <td>0.037447</td>\n",
       "      <td>-0.153542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>-0.000905</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.007515</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.002879</td>\n",
       "      <td>-0.001272</td>\n",
       "      <td>-0.000802</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>-0.005690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          c_0       c_1       c_2       c_3       c_4       c_5       c_6  \\\n",
       "LNR                                                                         \n",
       "2    4.002040  0.695311  0.141709 -0.248340 -0.078177 -0.186636 -0.228007   \n",
       "3    4.007755  0.700742  0.142745 -0.246705 -0.077638 -0.182470 -0.227757   \n",
       "4    3.996326  0.689880  0.140674 -0.249976 -0.078717 -0.190801 -0.228257   \n",
       "6    3.970465  0.785248 -0.197447  0.129687 -0.091095 -0.286309 -0.271982   \n",
       "7    3.996326  0.689880  0.140674 -0.249976 -0.078717 -0.190801 -0.228257   \n",
       "\n",
       "          c_7       c_8       c_9  ...     c_161     c_162     c_163  \\\n",
       "LNR                                ...                                 \n",
       "2   -0.041814  0.040093 -0.150729  ... -0.000169  0.002116  0.002593   \n",
       "3   -0.039235  0.042738 -0.147917  ... -0.002663  0.005137  0.002870   \n",
       "4   -0.044394  0.037447 -0.153542  ...  0.002325 -0.000905  0.002317   \n",
       "6   -0.127985  0.030960 -0.250130  ...  0.001588 -0.008212 -0.002803   \n",
       "7   -0.044394  0.037447 -0.153542  ...  0.002325 -0.000905  0.002317   \n",
       "\n",
       "        c_164     c_165     c_166     c_167     c_168     c_169     c_170  \n",
       "LNR                                                                        \n",
       "2    0.005166  0.003029  0.002074  0.000332  0.001077  0.002015 -0.002449  \n",
       "3    0.002816  0.004773  0.001269  0.001936  0.002956  0.001260  0.000792  \n",
       "4    0.007515  0.001286  0.002879 -0.001272 -0.000802  0.002771 -0.005690  \n",
       "6   -0.007783 -0.004655 -0.003404 -0.002669 -0.002122 -0.001001  0.002806  \n",
       "7    0.007515  0.001286  0.002879 -0.001272 -0.000802  0.002771 -0.005690  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailout_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_0</th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>c_6</th>\n",
       "      <th>c_7</th>\n",
       "      <th>c_8</th>\n",
       "      <th>c_9</th>\n",
       "      <th>...</th>\n",
       "      <th>c_162</th>\n",
       "      <th>c_163</th>\n",
       "      <th>c_164</th>\n",
       "      <th>c_165</th>\n",
       "      <th>c_166</th>\n",
       "      <th>c_167</th>\n",
       "      <th>c_168</th>\n",
       "      <th>c_169</th>\n",
       "      <th>c_170</th>\n",
       "      <th>RESPONSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LNR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.995876</td>\n",
       "      <td>0.665244</td>\n",
       "      <td>0.110896</td>\n",
       "      <td>-0.251562</td>\n",
       "      <td>-0.105309</td>\n",
       "      <td>-0.148803</td>\n",
       "      <td>-0.238394</td>\n",
       "      <td>-0.040665</td>\n",
       "      <td>0.035157</td>\n",
       "      <td>-0.146415</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000731</td>\n",
       "      <td>-0.001817</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>-0.000470</td>\n",
       "      <td>-0.001900</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.965506</td>\n",
       "      <td>0.756214</td>\n",
       "      <td>-0.215994</td>\n",
       "      <td>0.139012</td>\n",
       "      <td>-0.094574</td>\n",
       "      <td>-0.246466</td>\n",
       "      <td>-0.285659</td>\n",
       "      <td>-0.134052</td>\n",
       "      <td>0.035218</td>\n",
       "      <td>-0.240467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002953</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>-0.007351</td>\n",
       "      <td>-0.002974</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.004650</td>\n",
       "      <td>-0.009763</td>\n",
       "      <td>-0.001791</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.995876</td>\n",
       "      <td>0.665244</td>\n",
       "      <td>0.110896</td>\n",
       "      <td>-0.251562</td>\n",
       "      <td>-0.105309</td>\n",
       "      <td>-0.148803</td>\n",
       "      <td>-0.238394</td>\n",
       "      <td>-0.040665</td>\n",
       "      <td>0.035157</td>\n",
       "      <td>-0.146415</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000731</td>\n",
       "      <td>-0.001817</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>-0.000470</td>\n",
       "      <td>-0.001900</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.995876</td>\n",
       "      <td>0.665244</td>\n",
       "      <td>0.110896</td>\n",
       "      <td>-0.251562</td>\n",
       "      <td>-0.105309</td>\n",
       "      <td>-0.148803</td>\n",
       "      <td>-0.238394</td>\n",
       "      <td>-0.040665</td>\n",
       "      <td>0.035157</td>\n",
       "      <td>-0.146415</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000731</td>\n",
       "      <td>-0.001817</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>-0.000470</td>\n",
       "      <td>-0.001900</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>-0.371718</td>\n",
       "      <td>0.662183</td>\n",
       "      <td>0.634610</td>\n",
       "      <td>-0.667506</td>\n",
       "      <td>0.424038</td>\n",
       "      <td>0.379813</td>\n",
       "      <td>-0.116709</td>\n",
       "      <td>0.208385</td>\n",
       "      <td>0.038237</td>\n",
       "      <td>1.432644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137103</td>\n",
       "      <td>0.102245</td>\n",
       "      <td>0.280932</td>\n",
       "      <td>0.245000</td>\n",
       "      <td>-0.020560</td>\n",
       "      <td>0.317411</td>\n",
       "      <td>-0.063457</td>\n",
       "      <td>0.017113</td>\n",
       "      <td>0.070145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          c_0       c_1       c_2       c_3       c_4       c_5       c_6  \\\n",
       "LNR                                                                         \n",
       "1    3.995876  0.665244  0.110896 -0.251562 -0.105309 -0.148803 -0.238394   \n",
       "5    3.965506  0.756214 -0.215994  0.139012 -0.094574 -0.246466 -0.285659   \n",
       "9    3.995876  0.665244  0.110896 -0.251562 -0.105309 -0.148803 -0.238394   \n",
       "10   3.995876  0.665244  0.110896 -0.251562 -0.105309 -0.148803 -0.238394   \n",
       "11  -0.371718  0.662183  0.634610 -0.667506  0.424038  0.379813 -0.116709   \n",
       "\n",
       "          c_7       c_8       c_9  ...     c_162     c_163     c_164  \\\n",
       "LNR                                ...                                 \n",
       "1   -0.040665  0.035157 -0.146415  ... -0.000731 -0.001817  0.001947   \n",
       "5   -0.134052  0.035218 -0.240467  ...  0.002953  0.002411  0.000566   \n",
       "9   -0.040665  0.035157 -0.146415  ... -0.000731 -0.001817  0.001947   \n",
       "10  -0.040665  0.035157 -0.146415  ... -0.000731 -0.001817  0.001947   \n",
       "11   0.208385  0.038237  1.432644  ...  0.137103  0.102245  0.280932   \n",
       "\n",
       "        c_165     c_166     c_167     c_168     c_169     c_170  RESPONSE  \n",
       "LNR                                                                        \n",
       "1    0.001915 -0.000470 -0.001900  0.002229  0.002187  0.000647         0  \n",
       "5   -0.007351 -0.002974  0.005383 -0.004650 -0.009763 -0.001791         0  \n",
       "9    0.001915 -0.000470 -0.001900  0.002229  0.002187  0.000647         0  \n",
       "10   0.001915 -0.000470 -0.001900  0.002229  0.002187  0.000647         0  \n",
       "11   0.245000 -0.020560  0.317411 -0.063457  0.017113  0.070145         0  \n",
       "\n",
       "[5 rows x 172 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailout_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Unbalanced data\n",
    "\n",
    "The plot below shows that the data is higly unbalanced. I shall use to approaches. Provide a benchmark model using unbalanced data, then provide a benchmark model with Balanced data and use that to test on my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split data to features and labels\n",
    "LABEL = mailout_train_df['RESPONSE']\n",
    "FEATURES = mailout_train_df.drop('RESPONSE', axis=1)\n",
    "\n",
    "# Check Count for Response column in Mailout_Train\n",
    "num_rows = mailout_train_df.shape[0]\n",
    "\n",
    "# Response values\n",
    "cout = LABEL.value_counts()\n",
    "df_sp = pd.DataFrame({'RESPONSE': cout.index, '% of data': cout.values})\n",
    "df_sp['% of data'] = 100 * df_sp['% of data'] / num_rows\n",
    "\n",
    "# plot data on Response values\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=\"RESPONSE\", y=\"% of data\", data=df_sp)\n",
    "plt.rc('xtick', labelsize=25)  \n",
    "plt.rc('ytick', labelsize=25)\n",
    "plt.xlabel('RESPONSE', fontsize=15)\n",
    "plt.ylabel('% of data', fontsize=15)\n",
    "plt.title('Distribution of customers responses', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The positive response to mail campaign ratio is 0.01\n"
     ]
    }
   ],
   "source": [
    "# Ratio Calculation\n",
    "positive_response_ratio = LABEL.value_counts()[1]/LABEL.value_counts()[0]\n",
    "print ('The positive response to mail campaign ratio is {:.2f}'.format(positive_response_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmark Model\n",
    "I shall create a benchmark model. The goal is to train a supervised model and comapre its metrics to our supervised Linear Learner model previously tested on SageMaker ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV,cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, recall_score, precision_score, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize the data\n",
    "\n",
    "def randomize(X, Y):\n",
    "    permutation = np.random.permutation(Y.shape[0])\n",
    "    \n",
    "    X2 = X[permutation, :]\n",
    "    Y2 = Y[permutation]\n",
    "    \n",
    "    return X2, Y2\n",
    "\n",
    "\n",
    "X_train, y_train = randomize(np.asarray(FEATURES), np.asarray(LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data : (42962, 171)\n",
      "Shape of testing data : (42833, 171)\n",
      "Shape of y_pridict data : (42962,)\n"
     ]
    }
   ],
   "source": [
    "# shape of the dataset\n",
    "print('Shape of training data :', X_train.shape)\n",
    "print('Shape of testing data :', mailout_test_df.shape)\n",
    "print('Shape of y_pridict data :', y_train.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the dataset\n",
    "X_train.resize((42833, 171),refcheck=False)\n",
    "y_train.resize((42833),refcheck=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data : (42833, 171)\n",
      "Shape of testing data : (42833, 171)\n",
      "Shape of y_pridict data : (42833,)\n"
     ]
    }
   ],
   "source": [
    "# shape of the dataset\n",
    "print('Shape of training data :', X_train.shape)\n",
    "print('Shape of testing data :', mailout_test_df.shape)\n",
    "print('Shape of y_pridict data :',y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Define get_classifier function to fit different classifiers on balanced data\n",
    "# to find the best performing classifier algorithm\n",
    "def get_classifier(clf, param_grid, X=X_train, y=y_train):\n",
    "\n",
    "    # cross validation uses StratifiedKFold\n",
    "    # scoring roc_auc available as parameter\n",
    "    start = time.time()\n",
    "    grid = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='roc_auc', cv=5, verbose=0)\n",
    "    print(\"Training {} :\".format(clf.__class__.__name__))\n",
    "    grid.fit(X, y)\n",
    "    end = time.time()\n",
    "    time_taken = round(end-start,2)\n",
    "\n",
    "    print(clf.__class__.__name__)\n",
    "    print(\"Time taken : {} secs\".format(time_taken))\n",
    "    print(\"Best score : {}\".format(round(grid.best_score_,4)))\n",
    "    print(\"*\"*40)\n",
    "    \n",
    "    return grid.best_score_, grid.best_estimator_, time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select models to use\n",
    "\n",
    "lor_model = LogisticRegression(random_state=42, solver='liblinear') # LogisticRegression\n",
    "rfc_model = RandomForestClassifier(n_estimators=10, random_state=42) # RandomForestClassifier\n",
    "abc_model = AdaBoostClassifier(random_state=42) # AdaBoostClassifier\n",
    "xgb_model = XGBClassifier(objective='binary:logistic', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBClassifier :\n",
      "XGBClassifier\n",
      "Time taken : 315.62 secs\n",
      "Best score : 0.6339\n",
      "****************************************\n",
      "Training LogisticRegression :\n",
      "LogisticRegression\n",
      "Time taken : 12.5 secs\n",
      "Best score : 0.6562\n",
      "****************************************\n",
      "Training RandomForestClassifier :\n",
      "RandomForestClassifier\n",
      "Time taken : 54.93 secs\n",
      "Best score : 0.5069\n",
      "****************************************\n",
      "Training AdaBoostClassifier :\n",
      "AdaBoostClassifier\n",
      "Time taken : 238.92 secs\n",
      "Best score : 0.5883\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "# Find best classification algorithm\n",
    "clf_names = []\n",
    "clf_scores = []\n",
    "clf_best_ests = []\n",
    "clf_time_taken = []\n",
    "clf_dict = {}\n",
    "\n",
    "for clf in [xgb_model, lor_model, rfc_model, abc_model]:\n",
    "    best_score, best_est, time_taken = get_classifier(clf, {})\n",
    "    clf_names.append(clf.__class__.__name__)\n",
    "    clf_scores.append(best_score)\n",
    "    clf_best_ests.append(best_est)\n",
    "    clf_time_taken.append(time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_score</th>\n",
       "      <th>time_taken</th>\n",
       "      <th>best_est</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.633906</td>\n",
       "      <td>315.62</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.656174</td>\n",
       "      <td>12.50</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.506946</td>\n",
       "      <td>54.93</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.588307</td>\n",
       "      <td>238.92</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        best_score  time_taken  \\\n",
       "XGBClassifier             0.633906      315.62   \n",
       "LogisticRegression        0.656174       12.50   \n",
       "RandomForestClassifier    0.506946       54.93   \n",
       "AdaBoostClassifier        0.588307      238.92   \n",
       "\n",
       "                                                                 best_est  \n",
       "XGBClassifier           XGBClassifier(base_score=0.5, booster='gbtree'...  \n",
       "LogisticRegression      LogisticRegression(C=1.0, class_weight=None, d...  \n",
       "RandomForestClassifier  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "AdaBoostClassifier      (DecisionTreeClassifier(class_weight=None, cri...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the best model\n",
    "clf_dict['best_score'] = clf_scores\n",
    "clf_dict['time_taken'] = clf_time_taken\n",
    "clf_dict['best_est'] = clf_best_ests\n",
    "clf_df = pd.DataFrame(clf_dict, index=clf_names)\n",
    "clf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Paramaters tunning \n",
    "\n",
    "dual=[True,False]\n",
    "max_iter=[100,110,120,130,140]\n",
    "C = [1.0,1.5,2.0,2.5]\n",
    "param_grid_random = dict(dual=dual,max_iter=max_iter,C=C)\n",
    "lr = LogisticRegression(penalty='l2',solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.987626 using {'max_iter': 120, 'dual': False, 'C': 2.0}\n",
      "Execution time: 52.89104175567627sec\n"
     ]
    }
   ],
   "source": [
    "random = RandomizedSearchCV(\n",
    "    estimator=lr, \n",
    "    param_distributions=param_grid_random, \n",
    "    cv = 5, \n",
    "    n_jobs=-1)\n",
    "\n",
    "start_time = time.time()\n",
    "random_result = random.fit(X_train, y_train)\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42833, 171)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = mailout_test_df.values.astype('float32')\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target on test data [0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# predict the target on the test dataset\n",
    "y_pred = random_result.predict(X_test)\n",
    "print('\\nTarget on test data',y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 98.76%\n",
      "f1_score: 0.00%\n",
      "recall_score: 0.00%\n",
      "precision_score: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nyaribomaseru/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/nyaribomaseru/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Calculation of accuracy\n",
    "print ('accuracy_score: {:.2%}'.format(accuracy_score(y_train,y_pred )))\n",
    "\n",
    "# Calculation of f1 score\n",
    "print ('f1_score: {:.2%}'.format(f1_score(y_train, y_pred)))\n",
    "\n",
    "# Calculation of recall_score\n",
    "print ('recall_score: {:.2%}'.format(recall_score(y_train, y_pred)))\n",
    "\n",
    "# Calculation of precision_score\n",
    "print ('precision_score: {:.2%}'.format(precision_score(y_train, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These scores are very bad. We can see that our model predict 0 number of the pesrons supposed to be in the mail list \n",
    "#### (labeled 1). we can improve our model with different techniques as follow:\n",
    "- Oversample minority class\n",
    "- Tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The data is higly unbalanced. Below are steps to create a balanced dataset before we do traning and and testing\n",
    "\n",
    "### Oversample minority class\n",
    "To compensate imbalance in data we need to resample our data. For this data we use oversampling which can be defined as adding more copies of the minority class. Oversampling can be a good choice when we don’t have enough data to work with. In this project we will use the resampling module from Scikit-Learn to randomly replicate samples from the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    31829\n",
       "0    31829\n",
       "Name: RESPONSE, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balance the data\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate input features and target\n",
    "# y = label\n",
    "# X = features\n",
    "y = LABEL\n",
    "X = FEATURES\n",
    "\n",
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# concatenate our training data back together\n",
    "X = pd.concat([X_train, y_train], axis=1)\n",
    "# X = pd.concat([pd.DataFrame(X_train), pd.DataFrame(y_train)], axis=1)\n",
    "# separate minority and majority classes\n",
    "postive_response = X[X.RESPONSE==0]\n",
    "negative_response = X[X.RESPONSE==1]\n",
    "\n",
    "# upsample minority\n",
    "negative_response_upsampled = resample(negative_response,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(postive_response), # match number in majority class\n",
    "                          random_state=42) # reproducible results\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([postive_response, negative_response_upsampled])\n",
    "\n",
    "# check new class counts\n",
    "upsampled.RESPONSE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Unsampled data to X_train and Y_train set\n",
    "y_train = upsampled.RESPONSE\n",
    "X_train = upsampled.drop('RESPONSE', axis=1)\n",
    "\n",
    "balanced_df = pd.concat([pd.DataFrame(X_train), pd.DataFrame(y_train)], axis=1)\n",
    "X_feat = balanced_df.drop('RESPONSE', axis=1)#.values.astype('float32')\n",
    "y_feat = balanced_df.RESPONSE#.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data : (63658, 171)\n",
      "Shape of testing data : (42833, 171)\n",
      "Shape of y_pridict data : (63658,)\n"
     ]
    }
   ],
   "source": [
    "# shape of the dataset\n",
    "print('Shape of training data :', X_feat.shape)\n",
    "print('Shape of testing data :', mailout_test_df.shape)\n",
    "print('Shape of y_pridict data :', y_feat.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42833, 171)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = mailout_test_df.values.astype('float32')\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the test_x dataset\n",
    "test_x.resize((63658, 171),refcheck=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data : (63658, 171)\n",
      "Shape of testing data : (63658, 171)\n",
      "Shape of y_pridict data : (63658,)\n"
     ]
    }
   ],
   "source": [
    "# shape of the dataset\n",
    "print('Shape of training data :', X_feat.shape)\n",
    "print('Shape of testing data :', test_x.shape)\n",
    "print('Shape of y_pridict data :', y_feat.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Model\n",
    "Find a benchmark model to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Define get_classifier function to fit different classifiers on balanced data\n",
    "# to find the best performing classifier algorithm\n",
    "def get_classifier(clf, param_grid, X=X_feat, y=y_feat):\n",
    "\n",
    "    # cross validation uses StratifiedKFold\n",
    "    # scoring roc_auc available as parameter\n",
    "    start = time.time()\n",
    "    grid = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='roc_auc', cv=5, verbose=0)\n",
    "    print(\"Training {} :\".format(clf.__class__.__name__))\n",
    "    grid.fit(X, y)\n",
    "    end = time.time()\n",
    "    time_taken = round(end-start,2)\n",
    "\n",
    "    print(clf.__class__.__name__)\n",
    "    print(\"Time taken : {} secs\".format(time_taken))\n",
    "    print(\"Best score : {}\".format(round(grid.best_score_,4)))\n",
    "    print(\"*\"*40)\n",
    "    \n",
    "    return grid.best_score_, grid.best_estimator_, time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBClassifier :\n",
      "XGBClassifier\n",
      "Time taken : 396.09 secs\n",
      "Best score : 0.9608\n",
      "****************************************\n",
      "Training LogisticRegression :\n",
      "LogisticRegression\n",
      "Time taken : 16.84 secs\n",
      "Best score : 0.7627\n",
      "****************************************\n",
      "Training RandomForestClassifier :\n",
      "RandomForestClassifier\n",
      "Time taken : 29.22 secs\n",
      "Best score : 0.9927\n",
      "****************************************\n",
      "Training AdaBoostClassifier :\n",
      "AdaBoostClassifier\n",
      "Time taken : 244.34 secs\n",
      "Best score : 0.8209\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "# Find best classification algorithm\n",
    "for clf in [xgb_model, lor_model, rfc_model, abc_model]:\n",
    "    best_score, best_est, time_taken = get_classifier(clf, {})\n",
    "    clf_names.append(clf.__class__.__name__)\n",
    "    clf_scores.append(best_score)\n",
    "    clf_best_ests.append(best_est)\n",
    "    clf_time_taken.append(time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_score</th>\n",
       "      <th>time_taken</th>\n",
       "      <th>best_est</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.633906</td>\n",
       "      <td>315.62</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.656174</td>\n",
       "      <td>12.50</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.506946</td>\n",
       "      <td>54.93</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.588307</td>\n",
       "      <td>238.92</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.960828</td>\n",
       "      <td>396.09</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.762734</td>\n",
       "      <td>16.84</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.992677</td>\n",
       "      <td>29.22</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.820870</td>\n",
       "      <td>244.34</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        best_score  time_taken  \\\n",
       "XGBClassifier             0.633906      315.62   \n",
       "LogisticRegression        0.656174       12.50   \n",
       "RandomForestClassifier    0.506946       54.93   \n",
       "AdaBoostClassifier        0.588307      238.92   \n",
       "XGBClassifier             0.960828      396.09   \n",
       "LogisticRegression        0.762734       16.84   \n",
       "RandomForestClassifier    0.992677       29.22   \n",
       "AdaBoostClassifier        0.820870      244.34   \n",
       "\n",
       "                                                                 best_est  \n",
       "XGBClassifier           XGBClassifier(base_score=0.5, booster='gbtree'...  \n",
       "LogisticRegression      LogisticRegression(C=1.0, class_weight=None, d...  \n",
       "RandomForestClassifier  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "AdaBoostClassifier      (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "XGBClassifier           XGBClassifier(base_score=0.5, booster='gbtree'...  \n",
       "LogisticRegression      LogisticRegression(C=1.0, class_weight=None, d...  \n",
       "RandomForestClassifier  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "AdaBoostClassifier      (DecisionTreeClassifier(class_weight=None, cri...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_dict['best_score'] = clf_scores\n",
    "clf_dict['time_taken'] = clf_time_taken\n",
    "clf_dict['best_est'] = clf_best_ests\n",
    "clf_df = pd.DataFrame(clf_dict, index=clf_names)\n",
    "clf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsampled = rfc_model.fit(X=X_feat, y=y_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target on test data [0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# predict the target on the test dataset\n",
    "y_pred = unsampled.predict(test_x)\n",
    "print('\\nTarget on test data',y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 50.00%\n",
      "f1_score: 0.13%\n",
      "recall_score: 0.07%\n",
      "precision_score: 50.00%\n"
     ]
    }
   ],
   "source": [
    "# Calculation of accuracy\n",
    "print ('accuracy_score: {:.2%}'.format(accuracy_score(y_feat,y_pred )))\n",
    "\n",
    "# Calculation of f1 score\n",
    "print ('f1_score: {:.2%}'.format(f1_score(y_feat, y_pred)))\n",
    "\n",
    "# Calculation of recall_score\n",
    "print ('recall_score: {:.2%}'.format(recall_score(y_feat, y_pred)))\n",
    "\n",
    "# Calculation of precision_score\n",
    "print ('precision_score: {:.2%}'.format(precision_score(y_feat, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperparameterTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [200]\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "max_depth = [10, 20]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 5, 10] \n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 59.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.942018 using {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2', 'max_depth': 20, 'bootstrap': False}\n",
      "Execution time: 3619.877776861191sec\n"
     ]
    }
   ],
   "source": [
    "random = RandomizedSearchCV(\n",
    "    random_state=42,\n",
    "    estimator=rfc_model, \n",
    "    param_distributions=random_grid, \n",
    "    n_iter=10,\n",
    "    verbose=5,\n",
    "    cv = 5, \n",
    "    n_jobs=-1)\n",
    "\n",
    "start_time = time.time()\n",
    "rf_random_result = random.fit(X_train, y_train)\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (rf_random_result.best_score_, rf_random_result.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best params\n",
    "b_random_grid = {'n_estimators': 200, \n",
    "                 'min_samples_split': 2, \n",
    "                 'min_samples_leaf': 10, \n",
    "                 'max_features': 'log2', \n",
    "                 'max_depth': 20, \n",
    "                 'bootstrap': False}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_final = RandomForestClassifier(n_estimators = 200, \n",
    "          min_samples_split = 2, \n",
    "          min_samples_leaf = 10, \n",
    "          max_features = 'log2', \n",
    "          max_depth =20, \n",
    "          bootstrap = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = rfc_final.fit(X=X_feat, y=y_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target on test data [0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# predict the target on the test dataset\n",
    "y_pred_final = final_model.predict(test_x)\n",
    "print('\\nTarget on test data',y_pred_final) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 50.00%\n",
      "f1_score: 0.03%\n",
      "recall_score: 0.01%\n",
      "precision_score: 57.14%\n"
     ]
    }
   ],
   "source": [
    "# Calculation of accuracy\n",
    "print ('accuracy_score: {:.2%}'.format(accuracy_score(y_feat,y_pred_final )))\n",
    "\n",
    "# Calculation of f1 score\n",
    "print ('f1_score: {:.2%}'.format(f1_score(y_feat, y_pred_final)))\n",
    "\n",
    "# Calculation of recall_score\n",
    "print ('recall_score: {:.2%}'.format(recall_score(y_feat, y_pred_final)))\n",
    "\n",
    "# Calculation of precision_score\n",
    "print ('precision_score: {:.2%}'.format(precision_score(y_feat, y_pred_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31826,     3],\n",
       "       [31825,     4]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the metrics class\n",
    "cnf_matrix = confusion_matrix(y_feat,y_pred_final)\n",
    "cnf_matrix\n",
    "\n",
    "\n",
    "\n",
    "# confusion_matrix, accuracy_score, f1_score, recall_score, precision_score, make_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive: 4\n",
      "True Negative: 31826\n",
      "False Positive: 3\n",
      "False Negative: 31825\n"
     ]
    }
   ],
   "source": [
    "print ('True Positive: {}'.format(cnf_matrix[1][1]))\n",
    "print ('True Negative: {}'.format(cnf_matrix[0][0]))\n",
    "print ('False Positive: {}'.format(cnf_matrix[0][1]))\n",
    "print ('False Negative: {}'.format(cnf_matrix[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "lor_unsampled = lor_model.fit(X=X_feat, y=y_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target on test data [1 1 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# predict the target on the test dataset\n",
    "lr_y_pred = lor_unsampled.predict(test_x)\n",
    "print('\\nTarget on test data',lr_y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 49.55%\n",
      "f1_score: 32.36%\n",
      "recall_score: 24.14%\n",
      "precision_score: 49.09%\n"
     ]
    }
   ],
   "source": [
    "# Calculation of accuracy\n",
    "print ('accuracy_score: {:.2%}'.format(accuracy_score(y_feat,lr_y_pred )))\n",
    "\n",
    "# Calculation of f1 score\n",
    "print ('f1_score: {:.2%}'.format(f1_score(y_feat, lr_y_pred)))\n",
    "\n",
    "# Calculation of recall_score\n",
    "print ('recall_score: {:.2%}'.format(recall_score(y_feat, lr_y_pred)))\n",
    "\n",
    "# Calculation of precision_score\n",
    "print ('precision_score: {:.2%}'.format(precision_score(y_feat, lr_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_model_unsampled = abc_model.fit(X=X_feat, y=y_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target on test data [0 0 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# predict the target on the test dataset\n",
    "abc_y_pred = abc_model_unsampled.predict(test_x)\n",
    "print('\\nTarget on test data',abc_y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 50.48%\n",
      "f1_score: 43.57%\n",
      "recall_score: 38.24%\n",
      "precision_score: 50.63%\n"
     ]
    }
   ],
   "source": [
    "# Calculation of accuracy\n",
    "print ('accuracy_score: {:.2%}'.format(accuracy_score(y_feat,abc_y_pred )))\n",
    "\n",
    "# Calculation of f1 score\n",
    "print ('f1_score: {:.2%}'.format(f1_score(y_feat, abc_y_pred)))\n",
    "\n",
    "# Calculation of recall_score\n",
    "print ('recall_score: {:.2%}'.format(recall_score(y_feat, abc_y_pred)))\n",
    "\n",
    "# Calculation of precision_score\n",
    "print ('precision_score: {:.2%}'.format(precision_score(y_feat, abc_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
